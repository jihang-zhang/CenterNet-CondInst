{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import more dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from wheat_infer_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    arch = 'resnest50'\n",
    "    heads = {'hm': 1,\n",
    "             'wh': 2,\n",
    "             'reg': 2}\n",
    "    head_conv = 64\n",
    "    reg_offset = True\n",
    "    cat_spec_wh = False\n",
    "    load_model = '../exp/ctdet/resnest50_fpn/model_best_125.pth'\n",
    "    \n",
    "    # Image\n",
    "    img_size = 1024\n",
    "    in_scale = 1024 / img_size\n",
    "    down_ratio = 4\n",
    "    \n",
    "    mean = [0.214556, 0.317253, 0.315290], \n",
    "    std = [0.193879, 0.238036, 0.245211]\n",
    "    num_classes = 1\n",
    "    \n",
    "    pad = 31\n",
    "    \n",
    "    # Test\n",
    "    \n",
    "    batch_size = 4\n",
    "    K = 128\n",
    "    max_per_image = 128\n",
    "    \n",
    "    fix_res = False\n",
    "    test_scales = [1]\n",
    "    flip_test = False\n",
    "    nms = False\n",
    "    gpus = [0]\n",
    "    \n",
    "opt = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model & load pretrained weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseFPNNet(nn.Module):\n",
    "    def __init__(self, base_name, heads, head_conv=256):\n",
    "        super(PoseFPNNet, self).__init__()\n",
    "\n",
    "        base = smp.FPN(base_name, encoder_weights=None, decoder_dropout=0, decoder_segmentation_channels=64, upsampling=1)\n",
    "        self.encoder = base.encoder\n",
    "        self.decoder = base.decoder\n",
    "\n",
    "        self.heads = heads\n",
    "        for head in self.heads:\n",
    "            classes = self.heads[head]\n",
    "            fc = nn.Sequential(\n",
    "                nn.Conv2d(64, head_conv,\n",
    "                          kernel_size=3, padding=1, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(head_conv, classes,\n",
    "                          kernel_size=1, stride=1,\n",
    "                          padding=0, bias=True))\n",
    "            if 'hm' in head:\n",
    "                fc[-1].bias.data.fill_(-2.19)\n",
    "            else:\n",
    "                fill_fc_weights(fc)\n",
    "            self.__setattr__(head, fc)\n",
    "\n",
    "        del base\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        x = self.decoder(*features)\n",
    "\n",
    "        z = {}\n",
    "        for head in self.heads:\n",
    "            z[head] = self.__getattr__(head)(x)\n",
    "        return [z]\n",
    "\n",
    "    def freeze_backbone(self):\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.decoder.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def freeze_head(self, heads):\n",
    "        for head in heads:\n",
    "            for p in self.__getattr__(head).parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def set_mode(self, mode, is_freeze_bn=False):\n",
    "        self.mode = mode\n",
    "        if mode in ['eval', 'valid', 'test']:\n",
    "            self.eval()\n",
    "        elif mode in ['train']:\n",
    "            self.train()\n",
    "            if is_freeze_bn==True: ##freeze\n",
    "                for m in self.modules():\n",
    "                    if isinstance(m, nn.BatchNorm2d):\n",
    "                        m.eval()\n",
    "                        # m.weight.requires_grad = False\n",
    "                        # m.bias.requires_grad   = False\n",
    "\n",
    "def fill_fc_weights(layers):\n",
    "    for m in layers.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.normal_(m.weight, std=0.001)\n",
    "            # torch.nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "            # torch.nn.init.xavier_normal_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def get_pose_net(base_name, heads, head_conv):\n",
    "    model = PoseFPNNet(base_name, heads, head_conv)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_pose_net(opt.arch, opt.heads, opt.head_conv)\n",
    "device = torch.device('cuda') if opt.gpus[0] >= 0 else torch.device('cpu')\n",
    "checkpoint = torch.load(opt.load_model, map_location=device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "del checkpoint\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preapre labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147793, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR_INPUT = '../../input'\n",
    "DIR_TRAIN = f'{DIR_INPUT}/train'\n",
    "DIR_TEST = f'{DIR_INPUT}/test'\n",
    "\n",
    "train_df = pd.read_csv(f'{DIR_INPUT}/train.csv')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>source</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>834.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>226.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>377.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>834.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id  width  height   source      x      y      w      h\n",
       "0  b6ab77fd7   1024    1024  usask_1  834.0  222.0   56.0   36.0\n",
       "1  b6ab77fd7   1024    1024  usask_1  226.0  548.0  130.0   58.0\n",
       "2  b6ab77fd7   1024    1024  usask_1  377.0  504.0   74.0  160.0\n",
       "3  b6ab77fd7   1024    1024  usask_1  834.0   95.0  109.0  107.0\n",
       "4  b6ab77fd7   1024    1024  usask_1   26.0  144.0  124.0  117.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['x'] = -1\n",
    "train_df['y'] = -1\n",
    "train_df['w'] = -1\n",
    "train_df['h'] = -1\n",
    "\n",
    "def expand_bbox(x):\n",
    "    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n",
    "    if len(r) == 0:\n",
    "        r = [-1, -1, -1, -1]\n",
    "    return r\n",
    "\n",
    "train_df[['x', 'y', 'w', 'h']] = np.stack(train_df['bbox'].apply(lambda x: expand_bbox(x)))\n",
    "train_df.drop(columns=['bbox'], inplace=True)\n",
    "train_df['x'] = train_df['x'].astype(np.float)\n",
    "train_df['y'] = train_df['y'].astype(np.float)\n",
    "train_df['w'] = train_df['w'].astype(np.float)\n",
    "train_df['h'] = train_df['h'].astype(np.float)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WheatDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, opt, image_dir, img_id):\n",
    "        \n",
    "        self.opt = opt\n",
    "        \n",
    "        self.image_dir = image_dir\n",
    "        self.img_id = img_id\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_id)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.img_id[idx])\n",
    "        return img_path, self.img_id[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/wheat/annotations/val.json', 'r') as f:\n",
    "    val_data_dict = json.load(f)\n",
    "val_img_ids = [d['file_name'] for d in val_data_dict['images']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in valid set: 675\n"
     ]
    }
   ],
   "source": [
    "testdataset = WheatDatasetTest(opt, '../data/wheat/images', val_img_ids)\n",
    "print('Total number of images in valid set: {}'.format(len(testdataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import ast\n",
    "\n",
    "from numba import jit\n",
    "from typing import List, Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(gt, pr, form='pascal_voc') -> float:\n",
    "    \"\"\"Calculates the Intersection over Union.\n",
    "\n",
    "    Args:\n",
    "        gt: (np.ndarray[Union[int, float]]) coordinates of the ground-truth box\n",
    "        pr: (np.ndarray[Union[int, float]]) coordinates of the prdected box\n",
    "        form: (str) gt/pred coordinates format\n",
    "            - pascal_voc: [xmin, ymin, xmax, ymax]\n",
    "            - coco: [xmin, ymin, w, h]\n",
    "    Returns:\n",
    "        (float) Intersection over union (0.0 <= iou <= 1.0)\n",
    "    \"\"\"\n",
    "    if form == 'coco':\n",
    "        gt = gt.copy()\n",
    "        pr = pr.copy()\n",
    "\n",
    "        gt[2] = gt[0] + gt[2]\n",
    "        gt[3] = gt[1] + gt[3]\n",
    "        pr[2] = pr[0] + pr[2]\n",
    "        pr[3] = pr[1] + pr[3]\n",
    "\n",
    "    # Calculate overlap area\n",
    "    dx = min(gt[2], pr[2]) - max(gt[0], pr[0]) + 1\n",
    "    \n",
    "    if dx < 0:\n",
    "        return 0.0\n",
    "    \n",
    "    dy = min(gt[3], pr[3]) - max(gt[1], pr[1]) + 1\n",
    "\n",
    "    if dy < 0:\n",
    "        return 0.0\n",
    "\n",
    "    overlap_area = dx * dy\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = (\n",
    "            (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1) +\n",
    "            (pr[2] - pr[0] + 1) * (pr[3] - pr[1] + 1) -\n",
    "            overlap_area\n",
    "    )\n",
    "\n",
    "    return overlap_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(gts, pred, pred_idx, threshold = 0.5, form = 'pascal_voc', ious=None) -> int:\n",
    "    \"\"\"Returns the index of the 'best match' between the\n",
    "    ground-truth boxes and the prediction. The 'best match'\n",
    "    is the highest IoU. (0.0 IoUs are ignored).\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        pred: (List[Union[int, float]]) Coordinates of the predicted box\n",
    "        pred_idx: (int) Index of the current predicted box\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (int) Index of the best match GT box (-1 if no match above threshold)\n",
    "    \"\"\"\n",
    "    best_match_iou = -np.inf\n",
    "    best_match_idx = -1\n",
    "\n",
    "    for gt_idx in range(len(gts)):\n",
    "        \n",
    "        if gts[gt_idx][0] < 0:\n",
    "            # Already matched GT-box\n",
    "            continue\n",
    "        \n",
    "        iou = -1 if ious is None else ious[gt_idx][pred_idx]\n",
    "\n",
    "        if iou < 0:\n",
    "            iou = calculate_iou(gts[gt_idx], pred, form=form)\n",
    "            \n",
    "            if ious is not None:\n",
    "                ious[gt_idx][pred_idx] = iou\n",
    "\n",
    "        if iou < threshold:\n",
    "            continue\n",
    "\n",
    "        if iou > best_match_iou:\n",
    "            best_match_iou = iou\n",
    "            best_match_idx = gt_idx\n",
    "\n",
    "    return best_match_idx\n",
    "\n",
    "def calculate_precision(gts, preds, threshold = 0.5, form = 'coco', ious=None) -> float:\n",
    "    \"\"\"Calculates precision for GT - prediction pairs at one threshold.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n = len(preds)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    # for pred_idx, pred in enumerate(preds_sorted):\n",
    "    for pred_idx in range(n):\n",
    "\n",
    "        best_match_gt_idx = find_best_match(gts, preds[pred_idx], pred_idx,\n",
    "                                            threshold=threshold, form=form, ious=ious)\n",
    "\n",
    "        if best_match_gt_idx >= 0:\n",
    "            # True positive: The predicted box matches a gt box with an IoU above the threshold.\n",
    "            tp += 1\n",
    "            # Remove the matched GT box\n",
    "            gts[best_match_gt_idx] = -1\n",
    "\n",
    "        else:\n",
    "            # No match\n",
    "            # False positive: indicates a predicted box had no associated gt box.\n",
    "            fp += 1\n",
    "\n",
    "    # False negative: indicates a gt box had no associated predicted box.\n",
    "    fn = (gts.sum(axis=1) > 0).sum()\n",
    "\n",
    "    return tp / (tp + fp + fn)\n",
    "\n",
    "\n",
    "def calculate_image_precision(gts, preds, thresholds = (0.5, ), form = 'coco') -> float:\n",
    "    \"\"\"Calculates image precision.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        thresholds: (float) Different thresholds\n",
    "        form: (str) Format of the coordinates\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n_threshold = len(thresholds)\n",
    "    image_precision = 0.0\n",
    "    \n",
    "    ious = np.ones((len(gts), len(preds))) * -1\n",
    "    # ious = None\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        precision_at_threshold = calculate_precision(gts.copy(), preds, threshold=threshold,\n",
    "                                                     form=form, ious=ious)\n",
    "        image_precision += precision_at_threshold / n_threshold\n",
    "\n",
    "    return image_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92147bee8514dc5be8b2918c0c1dfcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=675.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation IOU: 0.6755\n"
     ]
    }
   ],
   "source": [
    "detector = CtdetDetector(opt, model)\n",
    "threshold = 0.3\n",
    "\n",
    "validation_image_precisions = []\n",
    "# iou_thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "iou_thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75]\n",
    "\n",
    "for img_path, img_id in tqdm(testdataset):\n",
    "    \n",
    "    ret = detector.run(img_path)\n",
    "    results = ret['results'][1]\n",
    "    results = results[results[:, 4] > threshold]\n",
    "\n",
    "    preds = results[:, :4]\n",
    "    preds = np.clip(preds, 0, 1024)\n",
    "    preds[:, 2] -= preds[:, 0]\n",
    "    preds[:, 3] -= preds[:, 1]\n",
    "    preds = preds.round().astype(int)\n",
    "\n",
    "    scores = results[:, 4]\n",
    "    \n",
    "    \n",
    "    sample_id = os.path.splitext(img_id)[0]\n",
    "\n",
    "    gt_boxes = train_df[train_df['image_id'] == sample_id][['x', 'y', 'w', 'h']].values\n",
    "    gt_boxes = gt_boxes.astype(np.int)\n",
    "\n",
    "    \n",
    "    # Sort highest confidence -> lowest confidence\n",
    "    preds_sorted_idx = np.argsort(scores)[::-1]\n",
    "    preds_sorted = preds[preds_sorted_idx]\n",
    "\n",
    "    \n",
    "    image_precision = calculate_image_precision(gt_boxes, preds_sorted,\n",
    "                                                thresholds=iou_thresholds,\n",
    "                                                form='coco')\n",
    "    \n",
    "    validation_image_precisions.append(image_precision)\n",
    "    \n",
    "print(\"Validation IOU: {0:.4f}\".format(np.mean(validation_image_precisions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation IOU: 0.6755"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
